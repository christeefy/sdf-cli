---
title: "Github & CI/CD"
description:
  "SDF is a powerful tool on its own, but its utility is amplified when integrated into CI/CD workflows."
---
 
SDF's static analyis can supercharge CI/CD workflows for data teams. By compiling your SQL on each pull request, SDF can statically ensure new updates to your models are valid SQL and do not break anything downstream. Additionally, SDF supports the use of code contracts in CI/CD. This feature allows users to define their own static tests, further enhancing the robustness and reliability of your data models. Unlike other CI/CD data tools, SDF checks everything statically, preventing you from having to incur compute costs to validate SQL and run impact analysis._createMdxContent

This guide will walk you through how to integrate SDF into an example CI/CD workflow. Specifically, we'll be using GitHub Actions to run `sdf compile` and `sdf test` on new pull requests and subsequent updates. This guide assumes you have a basic understanding of GitHub Actions and how to create a workflow file. If you're new to GitHub Actions, we recommend checking out the [official documentation](https://docs.github.com/en/actions).

If you'd like to skip ahead and see the final result, you can find the example repository [here](https://github.com/sdf-labs/github-action-example).

## Prerequisites

There are two open source GitHub repositories we'll be using today, to follow along, fork the starting repository and clone it to your local machine. 

- A GitHub account
- SDF Installed
- A GitHub repository cloned locally that can be used for testing. See [this guide](https://docs.github.com/en/repositories/creating-and-managing-repositories/quickstart-for-repositories) for how to set this up.

## Guide

<Steps>
    <Step title="Create an Example Workspace">
		To start off, we'll create a new SDF workspace. We'll skaffold our GitHub action around this workspace. Today, we'll be using the `pii_saas_platform` example. You can create a new workspace by running the following command:

		```shell	
		    sdf new --sample pii_saas_platform
		```

        <Note>
            This command should be run within the Git repository you'd like to test with. We recommend using a fresh repository for this example
        </Note>
	</Step>
    <Step title="Run Compile">
		Next, let's confirm our workspace is working as expected by running `sdf compile`. This command will compile all of the SQL in your workspace and ensure it is valid. If you have any errors in your SQL, this command will fail. 

        ```shell	
            sdf compile
        ```
	</Step>
    <Step title="Add the GitHub Action">
        Now that we have a working workspace, let's add a GitHub action to run `sdf compile` on each pull request. We'll need to add four files to our workspace: 
        
        1. **Dockerfile** - We can place this in the repository root, since this Docker image contains everything necessary to run SDF. Note if you're using DBT, you'll need to use a slightly different Dockerfile. We'll cover this later.
        2. **action.yml** - This defines the GitHub action itself. It should also be placed in the repository root.
        3. **entrypoint.sh** - This script will be run when the Docker container is run. It should be placed in the repository root.
        4. **workflow file** - This file will actually run the action. It should be placed in this path `.github/workflows/sdf.yml`.

        <CodeGroup>

        ```yaml .github/workflows/sdf.yml
        name: On Pull Request Run Compile

        on:
            push:
                branches:
                - main
            pull_request:

        jobs:
            dbt_init_challenge_job:
                runs-on: ubuntu-latest
                name: Run sdf compile
                steps:
                  - name: Checkout
                    uses: actions/checkout@v4
                  - name: sdf compile step
                    uses: ./ # Uses an action in the root directory
                    id: sdf
                    with:
                        command: 'sdf compile'
                        workspace_dir: '.' # Path to your SDF workspace
                        # Add your SDF credentials if you intend to run `sdf push` 
                        access_key: ${{ secrets.ACCESS_KEY }}
                        secret_key: ${{ secrets.SECRET_KEY }}
                        # (Optional) Add your compute provider credentials and other env vars here
                        snowflake_account_id: ${{ secrets.SNOWFLAKE_ACCOUNT_ID }}
                        snowflake_username: ${{ secrets.SNOWFLAKE_USERNAME }}
                        snowflake_password: ${{ secrets.SNOWFLAKE_PASSWORD }}
                        snowflake_role: ${{ secrets.SNOWFLAKE_ROLE }}
                        snowflake_warehouse: ${{ secrets.SNOWFLAKE_WH }}
                        dbt_target: "prod"

                  # Use the output from the `sdf` step
                  - name: Display the sdf output
                    if: always()
                    run: |
                        echo "### SDF Run Logs ðŸªµ" >> $GITHUB_STEP_SUMMARY
                        echo '```' >>$GITHUB_STEP_SUMMARY
                        echo "${{ steps.sdf.outputs.log }}" >>$GITHUB_STEP_SUMMARY
                        echo '```' >>$GITHUB_STEP_SUMMARY
        ```
        ```yaml action.yml
        # action.yml
    name: "dbt action"
    description: "Run sdf cli commands"
    inputs:
            command:
                description: "The sdf command to run"
                default: "sdf compile"
                required: true
            workspace_dir:
                description: "The directory of the workspace"
                default: "."
                required: true
            access_key:
                description: "The access key"
                required: true
            secret_key:
                description: "The secret key"
                required: true
            is_dbt:
                description: "Whether the workspace is dbt based or not"
                required: true
                default: ""
            dbt_target:
                description: "The dbt target"
                required: false

            # required if snowflake table provider is used
            snowflake_account_id:
                description: "The snowflake account id"
                required: false
            snowflake_username:
                description: "The snowflake username"
                required: false
            snowflake_password:
                description: "The snowflake password"
                required: false
            snowflake_role:
                description: "The snowflake role"
                required: false
            snowflake_warehouse:
                description: "The snowflake warehouse"
                required: false

    outputs:
            result:
                description: "The result (pass or failed)"
            log:
                description: "The log of the command"
    runs:
            using: "docker"
            image: "Dockerfile"
            args:
                - ${{ inputs.command }}
                - ${{ inputs.is_dbt }}
            env:
                WORKSPACE_DIR: ${{ inputs.workspace_dir }}
                ACCESS_KEY: ${{ inputs.access_key }}
                SECRET_KEY: ${{ inputs.secret_key }}

                SNOWFLAKE_ACCOUNT_ID: ${{ inputs.snowflake_account_id }}
                SNOWFLAKE_USERNAME: ${{ inputs.snowflake_username }}
                SNOWFLAKE_PASSWORD: ${{ inputs.snowflake_password }}
                SNOWFLAKE_ROLE: ${{ inputs.snowflake_role }}
                SNOWFLAKE_WAREHOUSE: ${{ inputs.snowflake_warehouse }}
                DBT_TARGET: ${{ inputs.dbt_target }}
    ```

    ```shell entrypoint.sh
    #!/bin/bash -l

    echo "workspace dir set as: \"${WORKSPACE_DIR}\""
    cd ${WORKSPACE_DIR}

    input_command=$1
    input_is_dbt=$2

    check_exit_status() {
        exit_status=$1
        command_log=$2
        echo "checking exit status: $exit_status"
        if [ $exit_status -ne 0 ]; then
            # Log the error message to GitHub output
            {
                echo 'log<<EOF'
                echo "Command failed with status $exit_status"
                echo "$command_log"
                echo EOF
            } >>$GITHUB_OUTPUT
            
            echo "result=failed" >>$GITHUB_OUTPUT
            exit $exit_status
        fi
    }

    # Check if the variable starts with 'sdf push'
    if [[ $input_command == "sdf push"* ]]; then
        echo "'sdf push' runs 'sdf auth login' using headless credentials"
        sdf auth login --access-key "${ACCESS_KEY}" --secret-key "${SECRET_KEY}"
        check_exit_status $? ""
    fi

    if [[ -n $input_is_dbt ]]; then
        echo "::group::Setting up dbt"
        source /.venv/bin/activate

        echo "running dbt deps"
        dbt deps
        check_exit_status $? ""

        echo "running dbt compile"
        dbt compile
        check_exit_status $? ""

        echo "running dbt compile done"
        sdf dbt refresh
        echo "::endgroup::"
        check_exit_status $? ""
    fi

    # run sdf auth login snwoflake if necessary
    snowflake_provider=$(yq .provider.type workspace.sdf.yml | grep snowflake | tail -1)
    if [[ -n $snowflake_provider ]]; then
        echo "snowflake provider used: running 'sdf auth login'"
        sdf auth login snowflake \
            --account-id "${SNOWFLAKE_ACCOUNT_ID}" --username "${SNOWFLAKE_USERNAME}" --password "${SNOWFLAKE_PASSWORD}" \
            --role "${SNOWFLAKE_ROLE}" --warehouse "${SNOWFLAKE_WAREHOUSE}"
        check_exit_status $? ""
    fi

    # run and save outputs
    echo "running command: $input_command"
    log=$($input_command 2>&1)
    exit_status=$?
    echo "$log"
    check_exit_status $exit_status "$log"

    {
        echo 'log<<EOF'
        echo "$log"
        echo EOF
    } >>$GITHUB_OUTPUT
    echo "result=passed" >>$GITHUB_OUTPUT
    ```
    </CodeGroup>
    

    ```dockerfile Dockerfile
    FROM rust:1.76.0-bookworm
    ARG SDF_VERSION=0.1.180

    # Install dependencies
    RUN apt-get update && apt-get install -y \
        yq \
        curl \
        gnupg \
        && rm -rf /var/lib/apt/lists/*

    # Install sdf
    RUN curl -LSfs https://cdn.sdf.com/releases/download/install.sh | bash -s -- --version ${SDF_VERSION}

    # Copy your code file from your action repository to the filesystem path `/` of the container
    COPY entrypoint.sh /entrypoint.sh

    # Set the code file as the entry point
    ENTRYPOINT ["/entrypoint.sh"]

    ```

    <Info>
        If you'd like to place your `action.yml` file in a different directory, you can change the `uses` field to point to the correct path.
    </Info>
    <Tip>
        The `action.yml` and `Dockerfile` above will one day be replaced by an official open source SDF GitHub action. For now, you can use this action to run `sdf compile` and `sdf test` in your CI/CD workflows.
    </Tip>

    Next, make sure your `entrypoint.sh` file is executable by running the following command in your terminal:
    ```shell
    chmod +x entrypoint.sh
    ```
    </Step>
    <Step title="(Optional) Edit the GitHub Action if Using SDF with DBT">
    If you're not using DBT alongside SDF, you can skip step. Otherwisem, you'll need to use the following `Dockerfile.dbt` instead of the `Dockerfile` above. This Dockerfile includes the necessary dependencies to run DBT alongside SDF.
    Furthermore, if you don't have the DBT `profiles.yml` configured in your DBT project (i.e. adjacent to your `dbt_project.yml`), you'll need to write the `profiles.yml` file in the GitHub action. Use the modified `sdf.yml` workflow file (called `sdf_dbt.yml`) below to accomplish this. 
    Note the example below is for a Snowflake configuration. 

    <Warning>
        This action will run `dbt compile`, so make sure to replace `[target-name]` and `[relative-path-to-your-dbt-project]` with your own values and ensure they properly map to values in your `dbt_project.yml`. Otherwise `dbt compile` will fail and the action will not be able to run.
    </Warning>

    <Tip>
        The snippet below for writing out a `profiles.yml` was contributed by [Chris Hronek](https://github.com/chrishronek). Thanks Chris!
    </Tip>
    
    <CodeGroup>
    ```dockerfile Dockerfile.dbt
    FROM python:3.12.2-bookworm
    ARG SDF_VERSION=0.1.180

    # Install dependencies
    RUN apt-get update && apt-get install -y \
        yq \
        curl \
        && rm -rf /var/lib/apt/lists/*

    # Install sdf
    RUN curl -LSfs https://cdn.sdf.com/releases/download/install.sh | bash -s -- --version ${SDF_VERSION}

    # Install dbt-snowflake plugin using pip
    RUN python3.12 -m venv .venv && . .venv/bin/activate \
        && python3 -m pip install dbt-snowflake==1.7.2 \
        && python3 -m pip install --upgrade dbt-core==1.7.9 \
        && python3 -m pip install protobuf==4.25.3

    # Copy your code file from your action repository to the filesystem path `/` of the container
    COPY entrypoint.sh /entrypoint.sh

    # Set the code file as the entry point
    ENTRYPOINT ["/entrypoint.sh"]
    ```
    ```yaml .github/workflows/sdf_dbt.yml
        name: On Pull Request Run Compile

        on:
            push:
                branches:
                - main
            pull_request:

        jobs:
            dbt_init_challenge_job:
                runs-on: ubuntu-latest
                name: Run sdf compile
                steps:
                  - name: Checkout
                    uses: actions/checkout@v4
                  - name: Generate dbt profile
                    run: |
                    echo "
                    [target-name]:
                        outputs:
                        prod:
                            type: snowflake
                            account: ${{ secrets.SNOWFLAKE_ACCOUNT_ID }}
                            user: ${{ secrets.SNOWFLAKE_USERNAME }}
                            password: ${{ secrets.SNOWFLAKE_PASSWORD }}
                            role: ${{ secrets.SNOWFLAKE_ROLE }}
                            database: ${{ secrets.SNOWFLAKE_DB }} 
                            warehouse: ${{ secrets.SNOWFLAKE_WH }}
                            schema: ${{ secrets.SNOWFLAKE_SCHEMA }}
                            threads: 1
                            client_session_keep_alive: False
                            query_tag: GITHUB_ACTIONS
                        target: prod
                    " > [relative-path-to-your-dbt-project]/profiles.yml  
                  - name: sdf compile step
                    uses: ./ # Uses an action in the root directory
                    id: sdf
                    with:
                        command: 'sdf compile'
                        is_dbt: true
                        workspace_dir: '.' # Path to your SDF workspace
                        # Add your SDF credentials if you intend to run `sdf push` 
                        access_key: ${{ secrets.ACCESS_KEY }}
                        secret_key: ${{ secrets.SECRET_KEY }}
                        # (Optional) Add your compute provider credentials and other env vars here
                        snowflake_account_id: ${{ secrets.SNOWFLAKE_ACCOUNT_ID }}
                        snowflake_username: ${{ secrets.SNOWFLAKE_USERNAME }}
                        snowflake_password: ${{ secrets.SNOWFLAKE_PASSWORD }}
                        snowflake_role: ${{ secrets.SNOWFLAKE_ROLE }}
                        snowflake_warehouse: ${{ secrets.SNOWFLAKE_WH }}
                        dbt_target: "prod"

                  # Use the output from the `sdf` step
                  - name: Display the sdf output
                    if: always()
                    run: |
                        echo "### SDF Run Logs ðŸªµ" >> $GITHUB_STEP_SUMMARY
                        echo '```' >>$GITHUB_STEP_SUMMARY
                        echo "${{ steps.sdf.outputs.log }}" >>$GITHUB_STEP_SUMMARY
                        echo '```' >>$GITHUB_STEP_SUMMARY
        ```
     </CodeGroup>
    </Step>
    <Step title="Create a Pull Request on GitHub">
        Now, we'll commit out changes to a new branch and push them to GitHub to see our new action _in action_. Let's call this branch `add-sdf-action`. 

        ```shell
        git checkout -b add-sdf-action && \
        git add . && \
        git commit -m "Add SDF workspace and GitHub Action" && \
        git push -u origin add-sdf-action
        ```
        <Warning>
            This will add _all staged changes_ to the new branch. If there is anything you don't want to commit, make sure to unstage or stash it before running `git add .`
        </Warning>

        Now that we have a new branch in our remote repository, let's make a pull request on GitHub. Follow this [official guide](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request) from GitHub to do so, and make sure to select our `sdf-add-action` branch as the branch to merge into `main`.

        Once the pull request is created, you should see our new GitHub action start running and succeed. Congrats! You've successfully integrated SDF into your CI/CD workflow.
        <img src="https://cdn.sdf.com/img/sdf-github-action-pending.png" />
        <img src="https://cdn.sdf.com/img/sdf-github-action-success.png" />
    </Step>
    <Step title="Test a Breaking Change (Optional)">
        If you'd like to see the action fail, you can make a breaking change to your SQL and push it to the `add-sdf-action` branch. This will trigger the GitHub action to run again, and it should fail. 

        To demonstrate SDF's static impact analysis, let's remove a column that's being used in a downstream model. This will cause the `sdf compile` command to fail, and in a perfect world, would prevent us from merging this update into our main branch.
        To do this, remove line `7` from the file found at `ddls/payment/public/invoices.sql`. This will remove the `payer_user_id` column from the `invoices` DDL.

        After committing the change, push it to the branch with an open pull request. You should see the GitHub action fail, and the pull request will not be mergeable if the repository is configured in this way.

        Here's an example job summary of an SDF compilation failure in CI/CD
        <img src="https://cdn.sdf.com/img/sdf-github-action-failure.png" />
    </Step>
</Steps>

## Summary

In this guide, we walked through how to integrate SDF into a CI/CD workflow using GitHub Actions. We created a new SDF workspace, added a GitHub action to run `sdf compile` on each pull request, and tested the action by making a breaking change to our SQL. By integrating SDF into your CI/CD workflow, you can ensure that your SQL is always valid and downstream models are compliant with your new changes. This can help prevent costly errors and ensure that your data is always reliable.

For a completed example of this guide, check out the [example repository](https://docs.github.com/en/repositories/creating-and-managing-repositories/quickstart-for-repositories)
