---
title: "Getting Started"
description: We're glad to see you here. Today we're going to install SDF and create a hello world project. Let's get started.
---

## Installing SDF
Installation is currently by invitation only. If you'd like to try SDF, please [request a demo](https://www.sdf.com/inquiries).

### Verify Installation

To verify that SDF is installed correctly, run the following command:

```shell
sdf --help
```

``` shell
SDF's modular SQL

Usage: sdf <COMMAND>

Commands:
  new      Create a new sdf workspace
  clean    Remove artifacts that sdf has generated in the past
  compile  Compile models
  run      Run models
  test     Test your models
  stats    Statistics for your data
  report   Report code quality
  check    Check code quality
  ai       Infer metadata like classifiers and add them optionally to the workspace
  lineage  Display lineage for a given table and/or column
  push     Push a local workspace to the SDF Service
  system   System maintenance, install and update
  auth     Authenticate CLI to services like SDF, AWS, OpenAI, etc
  man      Display reference material, like the CLI, dialect specific functions, schemas for authoring and interchange
  dbt      Initialize an sdf workspace from an existing dbt project
  lsp      
  help     Print this message or the help of the given subcommand(s)

Options:
  -h, --help     Print help
  -V, --version  Print version

```

For more on installing SDF, see [Install SDF](/guide/install). 

## Creating a Workspace

To create a new SDF Workspace, run the following command:

```shell
sdf new --sample hello && cd hello
```
After running the command, you will see the following output: 
 
``` shell
    Created hello/.gitignore
    Created hello/src/main.sql
    Created hello/workspace.sdf.yml
   Finished new in 0.221 secs

```

This will create a new directory with the name of your workspac . In this case, that's `hello`. Feel free to change it to whatever you'd like, as long as the name is a valid SQL identifier.


The directory will contain a `workspace.sdf.yml` file, which is the primary configuration file for your project. For more on this, see our [workspaces guide](/guide/workspaces).
Your workspace directory will also contain a `src` directory with a single `main.sql` file containing a single statement. The workspace includes the src directory via an `include` path. 
We will be compiling `main.sql`, and then executing the SQl statement.
Next, let's take a deeper look at your project.

<Note>
SDF uses a cache to fingerprint outputs and accelerate recomputation. This cache is by default located in the `.sdfcache/` directory.
The cache machine specific and should not be checked in to git. An appropriate `.gitignore` file is created as part of the `sdf new` command.
</Note>

## Exploring Your Project

Next we'll run the core command of SDF: [sdf compile](/reference/sdf-cli#sdf-compile). 
Compiling our project will *statically* analyze the workspace, all queries, all schemas referenced by the queries, and all metadata (such as types). This static analysis can be used to explore table schemas and column-level lineage. 

Then, we'll execute the query with SDF's integrated execution runtime, right on your machine.

Finally, we'll create a new SQL file in the `/src` directory called main2.sql, referncing main, and calling SDF's built in lineage command.

Let's give them a go.


<Steps>
    <Step title="Static Analysis with `sdf compile`">
        First we'll try `sdf compile --show all`. The `--show` flag allows you to modulate SDF's output and the `all` option indicates that we would like to see all schemas from all tables referenced in the workspace.
        ```shell
        sdf compile --show all
        ```
         
        Your output should look like:
``` shell
Working set 1 model file, 1 .sdf file
  Compiling hello.pub.main (./src/main.sql)

Schema hello.pub.main
+-------------+------------------+------------+
| column_name | data_type        | classifier |
+-------------+------------------+------------+
| column_1    | varchar not null |            |
| column_2    | varchar not null |            |
+-------------+------------------+------------+
   Finished 1 model [1 succeeded] in 0.480 secs

```
    </Step>
    <Step title="Execution with `sdf run`">
        Next, let's execute the query, using SDF as the database.
        ```shell
        sdf run --show all
        ```

``` shell
Working set 1 model file, 1 .sdf file
    Running hello.pub.main (./src/main.sql)

Table hello.pub.main
+----------+-----------------+
| column_1 | column_2        |
+----------+-----------------+
| hello    | Jeffrey Walters |
+----------+-----------------+
1 rows.
   Finished 1 model [1 succeeded] in 0.454 secs

```
    </Step>
    <Step title="Add a Second SQL File">
        Add a new file in the source directory called `main2.sql` with the query:
        ```sql main2.sql
        SELECT * FROM main;
        ```
    </Step>
    <Step title="Lineage with `sdf lineage`">
        For any properly compiling SDF workspace, SDF guarantees rich column level lineage. The command below specifies a particular column, in a particular table that we would like to inspect.
        ```shell
        sdf lineage main2 --column column_1
        ```

``` shell
Working set 2 model files, 1 .sdf file
  Compiling hello.pub.main (./src/main.sql)
  Compiling hello.pub.main2 (./src/main2.sql)
main2.column_1
│
│ copy
└──────┐
       main.column_1
   Finished 2 models [2 succeeded] in 0.467 secs

```
    </Step>

</Steps>



As you can see from the output, SDF has statically analyzed the query and determined there's a single non-nullable column named `column` and it's of type `varchar`. 
You'll also see an empty `classifier` block in the output. This is for metadata we'll attach to columns, but we'll get to that later.

In this guide we showed you just how easy it is to install SDF and run your first query.
