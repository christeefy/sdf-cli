---
title: "SDF CLI Reference"
description: "This document contains the help content for the sdf command-line program."
---

# Command-Line Help for `sdf`

This document contains the help content for the `sdf` command-line program.

**Command Overview:**

* [`sdf`↴](#sdf)
* [`sdf new`↴](#sdf-new)
* [`sdf clean`↴](#sdf-clean)
* [`sdf compile`↴](#sdf-compile)
* [`sdf run`↴](#sdf-run)
* [`sdf test`↴](#sdf-test)
* [`sdf stats`↴](#sdf-stats)
* [`sdf report`↴](#sdf-report)
* [`sdf check`↴](#sdf-check)
* [`sdf ai`↴](#sdf-ai)
* [`sdf ai classify`↴](#sdf-ai-classify)
* [`sdf lineage`↴](#sdf-lineage)
* [`sdf push`↴](#sdf-push)
* [`sdf system`↴](#sdf-system)
* [`sdf system update`↴](#sdf-system-update)
* [`sdf system uninstall`↴](#sdf-system-uninstall)
* [`sdf auth`↴](#sdf-auth)
* [`sdf auth login`↴](#sdf-auth-login)
* [`sdf auth login aws`↴](#sdf-auth-login-aws)
* [`sdf auth login openai`↴](#sdf-auth-login-openai)
* [`sdf auth login snowflake`↴](#sdf-auth-login-snowflake)
* [`sdf auth logout`↴](#sdf-auth-logout)
* [`sdf auth logout aws`↴](#sdf-auth-logout-aws)
* [`sdf auth logout openai`↴](#sdf-auth-logout-openai)
* [`sdf auth logout snowflake`↴](#sdf-auth-logout-snowflake)
* [`sdf auth status`↴](#sdf-auth-status)
* [`sdf man`↴](#sdf-man)
* [`sdf man cli`↴](#sdf-man-cli)
* [`sdf man functions`↴](#sdf-man-functions)
* [`sdf man definition-schema`↴](#sdf-man-definition-schema)
* [`sdf man information-schema`↴](#sdf-man-information-schema)
* [`sdf dbt`↴](#sdf-dbt)
* [`sdf dbt init`↴](#sdf-dbt-init)
* [`sdf dbt refresh`↴](#sdf-dbt-refresh)

## `sdf`

SDF's modular SQL

**Usage:** `sdf  COMMAND `

###### **Subcommands:**

* `new` — Create a new sdf workspace
* `clean` — Remove artifacts that sdf has generated in the past
* `compile` — Compile models
* `run` — Run models
* `test` — Test your models
* `stats` — Statistics for your data
* `report` — Report code quality
* `check` — Check code quality
* `ai` — Infer metadata like classifiers and add them optionally to the workspace
* `lineage` — Display lineage for a given table and/or column
* `push` — Push a local workspace to the SDF Service
* `system` — System maintenance, install and update
* `auth` — Authenticate CLI to services like SDF, AWS, OpenAI, etc
* `man` — Display reference material, like the CLI, dialect specific functions, schemas for authoring and interchange
* `dbt` — Initialize an sdf workspace from an existing dbt project

###### **Options:**

* `--no-parallel` — Do NOT run in parallel

  Possible values: `true`, `false`

* `--num-threads  NUM_THREADS ` — Number of threads to use for parallel operations. If unset, default is number of CPU cores. Must be greater than 0 if set
* `--stack-size  STACK_SIZE ` — Set stack size for worker thread, in bytes
* `--log-level  LOG_LEVEL ` — Set log level (by setting env var RUST_LOG)

  Possible values: `trace`, `debug`, `info`, `warn`, `error`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf new`

Create a new sdf workspace

**Usage:** `sdf new [OPTIONS] [PATH]`

###### **Arguments:**

* ` PATH ` — Create a new sdf workspace at  path 

###### **Options:**

* `--list-samples` — List all available samples

  Default value: `false`

  Possible values: `true`, `false`

* `--sample  SAMPLE ` — Create a workspace with the sample content at  path 
* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 
* `-s`, `--show  SHOW ` — Display progress messages

  Default value: `progress`

  Possible values: `progress`, `none`




## `sdf clean`

Remove artifacts that sdf has generated in the past

**Usage:** `sdf clean [OPTIONS]`

###### **Options:**

* `-e`, `--environment  ENVIRONMENT `
* `--path  PATH ` — Remove artifacts at  path  that sdf has created in the past [default: current workspace directory]
* `-s`, `--show  SHOW ` — Display progress messages

  Default value: `progress`

  Possible values: `progress`, `none`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf compile`

Compile models

**Usage:** `sdf compile [OPTIONS] [TARGETS]...`

###### **Arguments:**

* ` TARGETS ` — Compile only the given source dirs, files or tables [default: all models]

###### **Options:**

* `--infer-functions` — Infer function signature

  Default value: `false`

  Possible values: `true`, `false`

* `--infer-tables` — Infer function signature

  Default value: `false`

  Possible values: `true`, `false`

* `-e`, `--environment  ENVIRONMENT ` — Use this environment
* `-s`, `--show  SHOW ` — Display messages [default: progress if TARGETS is empty, all otherwise]

  Possible values: `all`, `progress`, `result`, `none`

* `-q`, `--query  QUERY ` — Supply a .sql file or provide a sql snippet on the cmd line, e.g. 'select * from t'
* `--stage  STAGE ` — Run the following stages [default: all stages]

  Possible values: `preprocess`, `parse`, `resolve`, `classify`, `execute`

* `--cache  CACHE ` — Controls cache use

  Default value: `read-write`

  Possible values: `read-write`, `write-only`, `read-only`, `none`

* `--no-cache` — Shorthand for cache policy none

  Default value: `false`

  Possible values: `true`, `false`

* `--save-assembly` — Saves assembly.sdf.yml and sdf.information_schema.* in sdfcache/profile/...

  Default value: `false`

  Possible values: `true`, `false`

* `--show-assembly` — ONLY FOR TEST: Shows assembly.sdf.yml on console

  Default value: `false`

  Possible values: `true`, `false`

* `--show-preprocessed` — ONLY FOR TEST: Shows preprocessed .sql on console

  Default value: `false`

  Possible values: `true`, `false`

* `--save-preprocessed` — ONLY FOR TEST: Save preprocessed .sql in compiled dir

  Default value: `false`

  Possible values: `true`, `false`

* `--vars  VARS ` — Supply var bindings as a yml file or provide them as string e.g. '(key: value)'
* `-x`, `--experimental` — Modern output

  Default value: `false`

  Possible values: `true`, `false`

* `--downstream` — Execute cmd not only the given  targets  but also for all its downstream artifacts

  Default value: `false`

  Possible values: `true`, `false`

* `--format  FORMAT ` — Show error tables in this format

  Default value: `table`

  Possible values: `table`, `csv`, `tsv`, `json`, `nd-json`, `yml`

* `--limit  LIMIT ` — Limiting number of shown rows. Run with --limit 0 to remove limit

  Default value: `10`
* `--no-propagate` — Do NOT perform propagate phase, short form of --stage resolve

  Default value: `false`

  Possible values: `true`, `false`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf run`

Run models

**Usage:** `sdf run [OPTIONS] [TARGETS]...`

###### **Arguments:**

* ` TARGETS ` — Run only the given source dirs, files or tables [default: all models]

###### **Options:**

* `-e`, `--environment  ENVIRONMENT ` — Use this environment
* `-s`, `--show  SHOW ` — Display messages [default: progress if TARGETS is empty, all otherwise]

  Possible values: `all`, `progress`, `result`, `none`

* `-q`, `--query  QUERY ` — Supply a .sql file or provide a sql snippet on the cmd line, e.g. 'select * from t'
* `--stage  STAGE ` — Run the following stages [default: all stages]

  Possible values: `preprocess`, `parse`, `resolve`, `classify`, `execute`

* `--cache  CACHE ` — Controls cache use

  Default value: `read-write`

  Possible values: `read-write`, `write-only`, `read-only`, `none`

* `--no-cache` — Shorthand for cache policy none

  Default value: `false`

  Possible values: `true`, `false`

* `--save-assembly` — Saves assembly.sdf.yml and sdf.information_schema.* in sdfcache/profile/...

  Default value: `false`

  Possible values: `true`, `false`

* `--show-assembly` — ONLY FOR TEST: Shows assembly.sdf.yml on console

  Default value: `false`

  Possible values: `true`, `false`

* `--show-preprocessed` — ONLY FOR TEST: Shows preprocessed .sql on console

  Default value: `false`

  Possible values: `true`, `false`

* `--save-preprocessed` — ONLY FOR TEST: Save preprocessed .sql in compiled dir

  Default value: `false`

  Possible values: `true`, `false`

* `--vars  VARS ` — Supply var bindings as a yml file or provide them as string e.g. '(key: value)'
* `-x`, `--experimental` — Modern output

  Default value: `false`

  Possible values: `true`, `false`

* `--downstream` — Execute cmd not only the given  targets  but also for all its downstream artifacts

  Default value: `false`

  Possible values: `true`, `false`

* `--format  FORMAT ` — Show error tables in this format

  Default value: `table`

  Possible values: `table`, `csv`, `tsv`, `json`, `nd-json`, `yml`

* `--limit  LIMIT ` — Limiting number of shown rows. Run with --limit 0 to remove limit

  Default value: `10`
* `--no-propagate` — Do NOT perform propagate phase, short form of --stage resolve

  Default value: `false`

  Possible values: `true`, `false`

* `-d`, `--date  DATE ` — Run command for this  date , use YYYY-MM-DD or YYYY-MM-DDTHH:MM format
* `--from  FROM ` — Run command for all dates from  from  (inclusive), use YYYY-MM-DD or YYYY-MM-DDTHH:MM format
* `--to  TO ` — Run command for all dates to  to   (exclusive), use YYYY-MM-DD or YYYY-MM-DDTHH:MM format [default: now]
* `--dry-run` — Plan command but don't evaluate it

  Default value: `false`

  Possible values: `true`, `false`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf test`

Test your models

**Usage:** `sdf test [OPTIONS] [TARGETS]...`

###### **Arguments:**

* ` TARGETS ` — Assess code (data) quality: use source dirs, files or tables to determine which code (data) contracts to run [default: all code (data) contracts]

###### **Options:**

* `-e`, `--environment  ENVIRONMENT ` — Use this environment
* `-s`, `--show  SHOW ` — Display messages [default: progress if TARGETS is empty, all otherwise]

  Possible values: `all`, `progress`, `result`, `none`

* `-q`, `--query  QUERY ` — Supply a .sql file or provide a sql snippet on the cmd line, e.g. 'select * from t'
* `--stage  STAGE ` — Run the following stages [default: all stages]

  Possible values: `preprocess`, `parse`, `resolve`, `classify`, `execute`

* `--cache  CACHE ` — Controls cache use

  Default value: `read-write`

  Possible values: `read-write`, `write-only`, `read-only`, `none`

* `--no-cache` — Shorthand for cache policy none

  Default value: `false`

  Possible values: `true`, `false`

* `--save-assembly` — Saves assembly.sdf.yml and sdf.information_schema.* in sdfcache/profile/...

  Default value: `false`

  Possible values: `true`, `false`

* `--show-assembly` — ONLY FOR TEST: Shows assembly.sdf.yml on console

  Default value: `false`

  Possible values: `true`, `false`

* `--show-preprocessed` — ONLY FOR TEST: Shows preprocessed .sql on console

  Default value: `false`

  Possible values: `true`, `false`

* `--save-preprocessed` — ONLY FOR TEST: Save preprocessed .sql in compiled dir

  Default value: `false`

  Possible values: `true`, `false`

* `--vars  VARS ` — Supply var bindings as a yml file or provide them as string e.g. '(key: value)'
* `-x`, `--experimental` — Modern output

  Default value: `false`

  Possible values: `true`, `false`

* `--downstream` — Execute cmd not only the given  targets  but also for all its downstream artifacts

  Default value: `false`

  Possible values: `true`, `false`

* `--format  FORMAT ` — Show error tables in this format

  Default value: `table`

  Possible values: `table`, `csv`, `tsv`, `json`, `nd-json`, `yml`

* `--limit  LIMIT ` — Limiting number of shown rows. Run with --limit 0 to remove limit

  Default value: `10`
* `--no-propagate` — Do NOT perform propagate phase, short form of --stage resolve

  Default value: `false`

  Possible values: `true`, `false`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf stats`

Statistics for your data

**Usage:** `sdf stats [OPTIONS] [TARGETS]...`

###### **Arguments:**

* ` TARGETS ` — Profile data quality: use source dirs, files or tables to determine which data statistics to run [default: all data stats]

###### **Options:**

* `-e`, `--environment  ENVIRONMENT ` — Use this environment
* `-s`, `--show  SHOW ` — Display messages [default: progress if TARGETS is empty, all otherwise]

  Possible values: `all`, `progress`, `result`, `none`

* `-q`, `--query  QUERY ` — Supply a .sql file or provide a sql snippet on the cmd line, e.g. 'select * from t'
* `--stage  STAGE ` — Run the following stages [default: all stages]

  Possible values: `preprocess`, `parse`, `resolve`, `classify`, `execute`

* `--cache  CACHE ` — Controls cache use

  Default value: `read-write`

  Possible values: `read-write`, `write-only`, `read-only`, `none`

* `--no-cache` — Shorthand for cache policy none

  Default value: `false`

  Possible values: `true`, `false`

* `--save-assembly` — Saves assembly.sdf.yml and sdf.information_schema.* in sdfcache/profile/...

  Default value: `false`

  Possible values: `true`, `false`

* `--show-assembly` — ONLY FOR TEST: Shows assembly.sdf.yml on console

  Default value: `false`

  Possible values: `true`, `false`

* `--show-preprocessed` — ONLY FOR TEST: Shows preprocessed .sql on console

  Default value: `false`

  Possible values: `true`, `false`

* `--save-preprocessed` — ONLY FOR TEST: Save preprocessed .sql in compiled dir

  Default value: `false`

  Possible values: `true`, `false`

* `--vars  VARS ` — Supply var bindings as a yml file or provide them as string e.g. '(key: value)'
* `-x`, `--experimental` — Modern output

  Default value: `false`

  Possible values: `true`, `false`

* `--downstream` — Execute cmd not only the given  targets  but also for all its downstream artifacts

  Default value: `false`

  Possible values: `true`, `false`

* `--format  FORMAT ` — Show error tables in this format

  Default value: `table`

  Possible values: `table`, `csv`, `tsv`, `json`, `nd-json`, `yml`

* `--limit  LIMIT ` — Limiting number of shown rows. Run with --limit 0 to remove limit

  Default value: `10`
* `--no-propagate` — Do NOT perform propagate phase, short form of --stage resolve

  Default value: `false`

  Possible values: `true`, `false`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf report`

Report code quality

**Usage:** `sdf report [OPTIONS] [TARGETS]...`

###### **Arguments:**

* ` TARGETS ` — Profile code (data) quality, use source dirs, files or tables to determine which code (data) reports to run [default: all code (data) reports]

###### **Options:**

* `-e`, `--environment  ENVIRONMENT ` — Use this environment
* `-s`, `--show  SHOW ` — Display messages [default: progress if TARGETS is empty, all otherwise]

  Possible values: `all`, `progress`, `result`, `none`

* `-q`, `--query  QUERY ` — Supply a .sql file or provide a sql snippet on the cmd line, e.g. 'select * from t'
* `--stage  STAGE ` — Run the following stages [default: all stages]

  Possible values: `preprocess`, `parse`, `resolve`, `classify`, `execute`

* `--cache  CACHE ` — Controls cache use

  Default value: `read-write`

  Possible values: `read-write`, `write-only`, `read-only`, `none`

* `--no-cache` — Shorthand for cache policy none

  Default value: `false`

  Possible values: `true`, `false`

* `--save-assembly` — Saves assembly.sdf.yml and sdf.information_schema.* in sdfcache/profile/...

  Default value: `false`

  Possible values: `true`, `false`

* `--show-assembly` — ONLY FOR TEST: Shows assembly.sdf.yml on console

  Default value: `false`

  Possible values: `true`, `false`

* `--show-preprocessed` — ONLY FOR TEST: Shows preprocessed .sql on console

  Default value: `false`

  Possible values: `true`, `false`

* `--save-preprocessed` — ONLY FOR TEST: Save preprocessed .sql in compiled dir

  Default value: `false`

  Possible values: `true`, `false`

* `--vars  VARS ` — Supply var bindings as a yml file or provide them as string e.g. '(key: value)'
* `-x`, `--experimental` — Modern output

  Default value: `false`

  Possible values: `true`, `false`

* `--downstream` — Execute cmd not only the given  targets  but also for all its downstream artifacts

  Default value: `false`

  Possible values: `true`, `false`

* `--format  FORMAT ` — Show error tables in this format

  Default value: `table`

  Possible values: `table`, `csv`, `tsv`, `json`, `nd-json`, `yml`

* `--limit  LIMIT ` — Limiting number of shown rows. Run with --limit 0 to remove limit

  Default value: `10`
* `--no-propagate` — Do NOT perform propagate phase, short form of --stage resolve

  Default value: `false`

  Possible values: `true`, `false`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf check`

Check code quality

**Usage:** `sdf check [OPTIONS] [TARGETS]...`

###### **Arguments:**

* ` TARGETS ` — Check code (data) quality: use source dirs, files or tables to determine which code (data) checks to run [default: all code (data) checks]

###### **Options:**

* `-e`, `--environment  ENVIRONMENT ` — Use this environment
* `-s`, `--show  SHOW ` — Display messages [default: progress if TARGETS is empty, all otherwise]

  Possible values: `all`, `progress`, `result`, `none`

* `-q`, `--query  QUERY ` — Supply a .sql file or provide a sql snippet on the cmd line, e.g. 'select * from t'
* `--stage  STAGE ` — Run the following stages [default: all stages]

  Possible values: `preprocess`, `parse`, `resolve`, `classify`, `execute`

* `--cache  CACHE ` — Controls cache use

  Default value: `read-write`

  Possible values: `read-write`, `write-only`, `read-only`, `none`

* `--no-cache` — Shorthand for cache policy none

  Default value: `false`

  Possible values: `true`, `false`

* `--save-assembly` — Saves assembly.sdf.yml and sdf.information_schema.* in sdfcache/profile/...

  Default value: `false`

  Possible values: `true`, `false`

* `--show-assembly` — ONLY FOR TEST: Shows assembly.sdf.yml on console

  Default value: `false`

  Possible values: `true`, `false`

* `--show-preprocessed` — ONLY FOR TEST: Shows preprocessed .sql on console

  Default value: `false`

  Possible values: `true`, `false`

* `--save-preprocessed` — ONLY FOR TEST: Save preprocessed .sql in compiled dir

  Default value: `false`

  Possible values: `true`, `false`

* `--vars  VARS ` — Supply var bindings as a yml file or provide them as string e.g. '(key: value)'
* `-x`, `--experimental` — Modern output

  Default value: `false`

  Possible values: `true`, `false`

* `--downstream` — Execute cmd not only the given  targets  but also for all its downstream artifacts

  Default value: `false`

  Possible values: `true`, `false`

* `--format  FORMAT ` — Show error tables in this format

  Default value: `table`

  Possible values: `table`, `csv`, `tsv`, `json`, `nd-json`, `yml`

* `--limit  LIMIT ` — Limiting number of shown rows. Run with --limit 0 to remove limit

  Default value: `10`
* `--no-propagate` — Do NOT perform propagate phase, short form of --stage resolve

  Default value: `false`

  Possible values: `true`, `false`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf ai`

Infer metadata like classifiers and add them optionally to the workspace

**Usage:** `sdf ai [OPTIONS]  COMMAND `

###### **Subcommands:**

* `classify` — Auto classify columns

###### **Options:**

* `-s`, `--show  SHOW `

  Default value: `all`

  Possible values: `all`, `progress`, `result`, `none`




## `sdf ai classify`

Auto classify columns

**Usage:** `sdf ai classify [OPTIONS] [TARGETS]...`

###### **Arguments:**

* ` TARGETS ` — Classify only the given source dirs, files or tables [default: all root tables]

###### **Options:**

* `-e`, `--environment  ENVIRONMENT ` — Scope inference to using this environment
* `--save-location  SAVE_LOCATION ` — Add inferred classifiers to this include path [default: ./src]
* `--classifiers  CLASSIFIERS ` — Infer these classifiers [default: all classifiers]
* `--no-use-of-samples` — Do NOT pass samples to inference engine

  Default value: `false`

  Possible values: `true`, `false`

* `--no-use-of-data` — Do NOT pass at most 5 data values to inference engine

  Default value: `false`

  Possible values: `true`, `false`

* `--no-use-of-description` — Do NOT pass table/column descriptions to inference engine

  Default value: `false`

  Possible values: `true`, `false`

* `-y`, `--yes` — Answer yes to all prompts

  Default value: `false`

  Possible values: `true`, `false`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf lineage`

Display lineage for a given table and/or column

**Usage:** `sdf lineage [OPTIONS] [TARGETS]...`

###### **Arguments:**

* ` TARGETS ` — Target selection: compute the lineage for the given source dirs, files or @tables [default: all models]

###### **Options:**

* `--column  COLUMN ` — The column for which to compute lineage
* `--forward` — Compute downstream lineage instead of the default upstream lineage

  Default value: `false`

  Possible values: `true`, `false`

* `--show-scans` — Display scan dependencies in addition to copy and mod dependencies. Unset by default

  Default value: `false`

  Possible values: `true`, `false`

* `--max-depth  MAX_DEPTH ` — Limiting the depth of shown lineage tree. Default value of 0 shows full lineage

  Default value: `0`
* `-e`, `--environment  ENVIRONMENT ` — Use this environment
* `-s`, `--show  SHOW ` — Display messages [default: progress if TARGETS is empty, all otherwise]

  Possible values: `all`, `progress`, `result`, `none`

* `-q`, `--query  QUERY ` — Supply a .sql file or provide a sql snippet on the cmd line, e.g. 'select * from t'
* `--stage  STAGE ` — Run the following stages [default: all stages]

  Possible values: `preprocess`, `parse`, `resolve`, `classify`, `execute`

* `--cache  CACHE ` — Controls cache use

  Default value: `read-write`

  Possible values: `read-write`, `write-only`, `read-only`, `none`

* `--no-cache` — Shorthand for cache policy none

  Default value: `false`

  Possible values: `true`, `false`

* `--save-assembly` — Saves assembly.sdf.yml and sdf.information_schema.* in sdfcache/profile/...

  Default value: `false`

  Possible values: `true`, `false`

* `--show-assembly` — ONLY FOR TEST: Shows assembly.sdf.yml on console

  Default value: `false`

  Possible values: `true`, `false`

* `--show-preprocessed` — ONLY FOR TEST: Shows preprocessed .sql on console

  Default value: `false`

  Possible values: `true`, `false`

* `--save-preprocessed` — ONLY FOR TEST: Save preprocessed .sql in compiled dir

  Default value: `false`

  Possible values: `true`, `false`

* `--vars  VARS ` — Supply var bindings as a yml file or provide them as string e.g. '(key: value)'
* `-x`, `--experimental` — Modern output

  Default value: `false`

  Possible values: `true`, `false`

* `--downstream` — Execute cmd not only the given  targets  but also for all its downstream artifacts

  Default value: `false`

  Possible values: `true`, `false`

* `--format  FORMAT ` — Show error tables in this format

  Default value: `table`

  Possible values: `table`, `csv`, `tsv`, `json`, `nd-json`, `yml`

* `--limit  LIMIT ` — Limiting number of shown rows. Run with --limit 0 to remove limit

  Default value: `10`
* `--no-propagate` — Do NOT perform propagate phase, short form of --stage resolve

  Default value: `false`

  Possible values: `true`, `false`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf push`

Push a local workspace to the SDF Service

**Usage:** `sdf push [OPTIONS] [TARGETS]...`

###### **Arguments:**

* ` TARGETS ` — Target selection: push only the given source dirs, files or tables [default: current workspace directory]

###### **Options:**

* `--delete` — Delete this workspace from the SDF Service

  Default value: `false`

  Possible values: `true`, `false`

* `-y`, `--yes` — Answer yes to all prompts which include credentials' uploading to the console when using a table provider

  Default value: `false`

  Possible values: `true`, `false`

* `-d`, `--dry-run` — No changes will be made to the console when this is set

  Default value: `false`

  Possible values: `true`, `false`

* `-e`, `--environment  ENVIRONMENT ` — Use this environment
* `-s`, `--show  SHOW ` — Display messages [default: progress if TARGETS is empty, all otherwise]

  Possible values: `all`, `progress`, `result`, `none`

* `-q`, `--query  QUERY ` — Supply a .sql file or provide a sql snippet on the cmd line, e.g. 'select * from t'
* `--stage  STAGE ` — Run the following stages [default: all stages]

  Possible values: `preprocess`, `parse`, `resolve`, `classify`, `execute`

* `--cache  CACHE ` — Controls cache use

  Default value: `read-write`

  Possible values: `read-write`, `write-only`, `read-only`, `none`

* `--no-cache` — Shorthand for cache policy none

  Default value: `false`

  Possible values: `true`, `false`

* `--save-assembly` — Saves assembly.sdf.yml and sdf.information_schema.* in sdfcache/profile/...

  Default value: `false`

  Possible values: `true`, `false`

* `--show-assembly` — ONLY FOR TEST: Shows assembly.sdf.yml on console

  Default value: `false`

  Possible values: `true`, `false`

* `--show-preprocessed` — ONLY FOR TEST: Shows preprocessed .sql on console

  Default value: `false`

  Possible values: `true`, `false`

* `--save-preprocessed` — ONLY FOR TEST: Save preprocessed .sql in compiled dir

  Default value: `false`

  Possible values: `true`, `false`

* `--vars  VARS ` — Supply var bindings as a yml file or provide them as string e.g. '(key: value)'
* `-x`, `--experimental` — Modern output

  Default value: `false`

  Possible values: `true`, `false`

* `--downstream` — Execute cmd not only the given  targets  but also for all its downstream artifacts

  Default value: `false`

  Possible values: `true`, `false`

* `--format  FORMAT ` — Show error tables in this format

  Default value: `table`

  Possible values: `table`, `csv`, `tsv`, `json`, `nd-json`, `yml`

* `--limit  LIMIT ` — Limiting number of shown rows. Run with --limit 0 to remove limit

  Default value: `10`
* `--no-propagate` — Do NOT perform propagate phase, short form of --stage resolve

  Default value: `false`

  Possible values: `true`, `false`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf system`

System maintenance, install and update

**Usage:** `sdf system [OPTIONS]  COMMAND `

###### **Subcommands:**

* `update` — Update sdf in place to the latest version
* `uninstall` — Uninstall sdf from the system

###### **Options:**

* `-s`, `--show  SHOW ` — Display messages

  Default value: `progress`

  Possible values: `progress`, `none`




## `sdf system update`

Update sdf in place to the latest version

**Usage:** `sdf system update`

###### **Options:**

* `--version  VERSION ` — Update sdf to this  version   [default: latest version]



## `sdf system uninstall`

Uninstall sdf from the system

**Usage:** `sdf system uninstall`



## `sdf auth`

Authenticate CLI to services like SDF, AWS, OpenAI, etc

**Usage:** `sdf auth [OPTIONS]  COMMAND `

###### **Subcommands:**

* `login` — 
* `logout` — Log out of SDF Service
* `status` — Show status of credentials / tokens

###### **Options:**

* `-e`, `--environment  ENVIRONMENT ` — Use this environment
* `-s`, `--show  SHOW ` — Display messages [default: progress if TARGETS is empty, all otherwise]

  Possible values: `all`, `progress`, `result`, `none`

* `-q`, `--query  QUERY ` — Supply a .sql file or provide a sql snippet on the cmd line, e.g. 'select * from t'
* `--stage  STAGE ` — Run the following stages [default: all stages]

  Possible values: `preprocess`, `parse`, `resolve`, `classify`, `execute`

* `--cache  CACHE ` — Controls cache use

  Default value: `read-write`

  Possible values: `read-write`, `write-only`, `read-only`, `none`

* `--no-cache` — Shorthand for cache policy none

  Default value: `false`

  Possible values: `true`, `false`

* `--save-assembly` — Saves assembly.sdf.yml and sdf.information_schema.* in sdfcache/profile/...

  Default value: `false`

  Possible values: `true`, `false`

* `--show-assembly` — ONLY FOR TEST: Shows assembly.sdf.yml on console

  Default value: `false`

  Possible values: `true`, `false`

* `--show-preprocessed` — ONLY FOR TEST: Shows preprocessed .sql on console

  Default value: `false`

  Possible values: `true`, `false`

* `--save-preprocessed` — ONLY FOR TEST: Save preprocessed .sql in compiled dir

  Default value: `false`

  Possible values: `true`, `false`

* `--vars  VARS ` — Supply var bindings as a yml file or provide them as string e.g. '(key: value)'
* `-x`, `--experimental` — Modern output

  Default value: `false`

  Possible values: `true`, `false`

* `--downstream` — Execute cmd not only the given  targets  but also for all its downstream artifacts

  Default value: `false`

  Possible values: `true`, `false`

* `--format  FORMAT ` — Show error tables in this format

  Default value: `table`

  Possible values: `table`, `csv`, `tsv`, `json`, `nd-json`, `yml`

* `--limit  LIMIT ` — Limiting number of shown rows. Run with --limit 0 to remove limit

  Default value: `10`
* `--no-propagate` — Do NOT perform propagate phase, short form of --stage resolve

  Default value: `false`

  Possible values: `true`, `false`

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 



## `sdf auth login`

**Usage:** `sdf auth login [OPTIONS] [COMMAND]`

###### **Subcommands:**

* `aws` — Configure how to authenticate with AWS
* `openai` — Configure how to authenticate with OpenAI
* `snowflake` — Configure how to authenticate with Snowflake

###### **Options:**

* `-n`, `--name  NAME ` — Name of the credential to use
* `--id-token  ID_TOKEN ` — Path to a file containing an OIDC identity token (a JWT)
* `--access-key  ACCESS_KEY ` — Access key for headless authentication
* `--secret-key  SECRET_KEY ` — Secret key for headless authentication
* `--credentials-dir  CREDENTIALS_DIR ` — Path to the file where credentials will be stored (default is platform specific)



## `sdf auth login aws`

Configure how to authenticate with AWS

**Usage:** `sdf auth login aws [OPTIONS]`

###### **Options:**

* `-n`, `--name  NAME ` — Name of the credential to use
* `--default-region  DEFAULT_REGION ` — AWS Region to use (default: us-east-1)

  Default value: `us-east-1`
* `--profile  PROFILE ` — AWS profile to use, as usually defined in ~/.aws/config or ~/.aws/credentials
* `--role-arn  ROLE_ARN ` — ARN of the role to assume
* `--external-id  EXTERNAL_ID ` — External ID to use when assuming the role
* `--use-web-identity` — Use web identity to authenticate

  Default value: `false`

  Possible values: `true`, `false`

* `--bucket-region-map  BUCKET_REGION_MAP ` — Mapping of bucket names to regions
* `--credentials-dir  CREDENTIALS_DIR ` — Path to the file where credentials will be stored (default is platform specific)
* `--access-key-id  ACCESS_KEY_ID ` — AWS access key id
* `--secret-access-key  SECRET_ACCESS_KEY ` — AWS secret access key



## `sdf auth login openai`

Configure how to authenticate with OpenAI

**Usage:** `sdf auth login openai [OPTIONS] --api-key  API_KEY `

###### **Options:**

* `-n`, `--name  NAME ` — Name of the credential to use
* `--api-key  API_KEY ` — Mapping of bucket names to regions
* `--credentials-dir  CREDENTIALS_DIR ` — Path to the file where credentials will be stored (default is platform specific)



## `sdf auth login snowflake`

Configure how to authenticate with Snowflake

**Usage:** `sdf auth login snowflake [OPTIONS] --account-id  ACCOUNT_ID  --username  USERNAME `

###### **Options:**

* `-n`, `--name  NAME ` — Name of the credential to use
* `-a`, `--account-id  ACCOUNT_ID ` — Snowflake account id
* `-U`, `--username  USERNAME ` — Snowflake username
* `-P`, `--password  PASSWORD ` — Snowflake password
* `-r`, `--role  ROLE ` — Snowflake role
* `-W`, `--warehouse  WAREHOUSE ` — Snowflake warehouse
* `--credentials-dir  CREDENTIALS_DIR ` — Path to the file where credentials will be stored (default is platform specific)



## `sdf auth logout`

Log out of SDF Service

**Usage:** `sdf auth logout [OPTIONS] [COMMAND]`

###### **Subcommands:**

* `aws` — Logout from AWS
* `openai` — Logout from OpenAI
* `snowflake` — Logout from Snowflake

###### **Options:**

* `-n`, `--name  NAME ` — Name of the credential to use
* `--credentials-dir  CREDENTIALS_DIR ` — Path to the file where credentials are be stored (default is platform specific)



## `sdf auth logout aws`

Logout from AWS

**Usage:** `sdf auth logout aws`



## `sdf auth logout openai`

Logout from OpenAI

**Usage:** `sdf auth logout openai`



## `sdf auth logout snowflake`

Logout from Snowflake

**Usage:** `sdf auth logout snowflake`



## `sdf auth status`

Show status of credentials / tokens

**Usage:** `sdf auth status [OPTIONS]`

###### **Options:**

* `--credentials-dir  CREDENTIALS_DIR ` — Path to the file where credentials will be stored (default is platform specific)



## `sdf man`

Display reference material, like the CLI, dialect specific functions, schemas for authoring and interchange

**Usage:** `sdf man [OPTIONS]  COMMAND `

###### **Subcommands:**

* `cli` — Display SDF's command line interface
* `functions` — Display SDF's functions definitions
* `definition-schema` — Display SDF's yml blocks as a json schema doc [only: json]
* `information-schema` — Display SDF's deploy structure as a json schema doc [only: json] Display SDF's information schemas [only: sql]

###### **Options:**

* `-s`, `--show  SHOW ` — Display messages [default: progress]

  Default value: `progress`

  Possible values: `progress`, `none`




## `sdf man cli`

Display SDF's command line interface

**Usage:** `sdf man cli [OPTIONS]`

###### **Options:**

* `--format  FORMAT ` — Format reference material in this  format  [only: markdown]

  Possible values: `sql`, `yml`, `markdown`, `json`




## `sdf man functions`

Display SDF's functions definitions

**Usage:** `sdf man functions [OPTIONS]`

###### **Options:**

* `--dialect  DIALECT ` — Dialect for all functions

  Default value: `presto`

  Possible values: `snowflake`, `presto`, `bigquery`, `redshift`, `spark-lp`

* `--section  SECTION ` — Section to display [ section  value must appear in the function registry]

  Default value: `all`
* `--format  FORMAT ` — Format reference material in this  format  [default: markdown | yml]

  Possible values: `sql`, `yml`, `markdown`, `json`




## `sdf man definition-schema`

Display SDF's yml blocks as a json schema doc [only: json]

**Usage:** `sdf man definition-schema [OPTIONS]`

###### **Options:**

* `--format  FORMAT ` — Format reference material in this  format  [only: json]

  Possible values: `sql`, `yml`, `markdown`, `json`




## `sdf man information-schema`

Display SDF's deploy structure as a json schema doc [only: json] Display SDF's information schemas [only: sql]

**Usage:** `sdf man information-schema [OPTIONS]`

###### **Options:**

* `--format  FORMAT ` — Format reference material in this  format  [only: sql]

  Possible values: `sql`, `yml`, `markdown`, `json`




## `sdf dbt`

Initialize an sdf workspace from an existing dbt project

**Usage:** `sdf dbt [OPTIONS]  COMMAND `

###### **Subcommands:**

* `init` — Initialize a sdf workspace from a dbt project -- best effort
* `refresh` — Re-initialize a sdf workspace from a dbt project -- best effort

###### **Options:**

* `--cache-dir  CACHE_DIR ` — Set the  cache-dir  for this session
* `--credentials-dir  CREDENTIALS_DIR ` — Read the credentials from  credentials-dir 
* `-s`, `--show  SHOW ` — Display messages

  Default value: `progress`

  Possible values: `progress`, `none`




## `sdf dbt init`

Initialize a sdf workspace from a dbt project -- best effort

**Usage:** `sdf dbt init [OPTIONS]`

###### **Options:**

* `--target  TARGET ` — Use this DBT target over the default target in profiles.yml
* `--profiles-dir  PROFILES_DIR ` — Use this DBT profile instead of the defaults at ~/.dbt/profile.yml -- (note dbt uses --profile_dir, this CLI uses --profile-dir)
* `--workspace-dir  WORKSPACE_DIR ` — Specifies the workspace directory where we expect to see manifest and dbt project files The SDF workspace file will be placed in the same directory. Default: current directory
* `-n`, `--no-save` — Skip saving and overwriting the workspace file

  Default value: `false`

  Possible values: `true`, `false`

* `-c`, `--config  CONFIG ` — Supply a config yml file or provide config as yml string e.g. '(key: value)'



## `sdf dbt refresh`

Re-initialize a sdf workspace from a dbt project -- best effort

**Usage:** `sdf dbt refresh [OPTIONS]`

###### **Options:**

* `--target  TARGET ` — Use this DBT target over the default target in profiles.yml
* `--profiles-dir  PROFILES_DIR ` — Use this DBT profile instead of the defaults at ~/.dbt/profile.yml -- (note dbt uses --profile_dir, this CLI uses --profile-dir)
* `--workspace-dir  WORKSPACE_DIR ` — Specifies the workspace directory where we expect to see manifest and dbt project files The SDF workspace file will be placed in the same directory. Default: current directory
* `-n`, `--no-save` — Skip saving and overwriting the workspace file

  Default value: `false`

  Possible values: `true`, `false`

* `-c`, `--config  CONFIG ` — Supply a config yml file or provide config as yml string e.g. '(key: value)'



   Finished man in 0.004 secs

