---
title: "SDF YML Schema"
---

## Block: `Workspace`
|Field | Type | Description|
| :---- | :--- | :------- |
`edition:` | `string`| The SDF edition, should always be 1 (for now)|
`name:` | `string`| The name of this workspace (defaults to the workspace directory name if not given) Name must be set for deployment.|
`description:` | `string`| A description of this workspace|
`repository:` | `string`| The URL of the workspace source repository (defaults to 'none' if no repository is given)|
`remote-location:` | `string`| The default output object store location, e.g. 's3://bucket/key/' where key is optional|
`includes:` | `array`| An array of directories and filenames containing .sql and .sdf.yml files|
`excludes:` | `array`| An array of directories and filenames to be skipped when resolving includes|
`references:` | `array`| An array of paths to other workspaces, i.e. .sql and .yml files Todo why do we skip this serialization?|
`dialect:` | `UNKNOWN`| The dialect of this workspace. If not set, defaults to Presto dialect|
`compute:` | `UNKNOWN`| The compute platform for this workspace. If not set, defaults to Local|
`default-catalog:` | `string`| Defines a default catalog (If not set, defaults to the workspace name)|
`default-schema:` | `string`| Defines a default schema (If not set, defaults to 'pub')|
`default-profile:` | `string`| Defines the default profile (if not set, defaults to 'dbg')|
`source-locations:` | `array`| Workspace defined by these set of files|
`vars:` | `object`| A map of named values for setting SQL variables from your environment Ex. -dt: dt, used in SQL as @dt, an in Jinja as {{ dt }}|
`preprocessor:` | `Preprocessor?`| Experimental: This project has jinja, sql_vars, and sql_macros|
`default-severity:` | `UNKNOWN`| The default severity for this tables tests and checks|
`is-dbt-project:` | `boolean?`| Experimental: This is a dbt project..|
## Block: `Table`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| undefined|
`description:` | `string?`| undefined|
`dialect:` | `Dialect?`| The dialect of this table, defaults to `presto`|
`compute:` | `ComputeKind?`| The compute platform for evaluating the query populating this table, defaults to `local`|
`table-type:` | `TableType?`| The table-type of this table|
`dependencies:` | `array`| ALl table dependencies (syntax: catalog.schema.table)|
`columns:` | `array`| The columns of the schema: name, type, metadata|
`partitioned-by:` | `array`| The partitioning format of the table|
`default-severity:` | `UNKNOWN`| The default severity for this tables tests and checks|
`constraints:` | `array`| undefined|
`schedule:` | `string`| The schedule of the table [expressed as cron]|
`starting:` | `string`| The first date of the table [expressed by prefixes of RFC 33]|
`classifiers:` | `array`| An array of classifier references|
`reclassify:` | `array`| Array of reclassify instructions for changing the attached classifier labels|
`lineage:` | `Lineage?`| Lineage, a tagged array of column references|
`location:` | `string?`| Data is at this location|
`file-format:` | `FileFormat?`| Store table in this format [only for external tables]|
`with-header:` | `boolean?`| CSV data has a header [only for external tables]|
`delimiter:` | `string?`| CSV data is separated by this delimiter [only for external tables]|
`compression:` | `CompressionType?`| Json or CSV data is compressed with this method [only for external tables]|
`source-locations:` | `array`| Table is defined by these .sql and/or .sdf files|
## Block: `Classifier`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| The name of the classifier type|
`description:` | `string`| A description of this classifier type|
`labels:` | `array`| Named classifier labels|
`scope:` | `UNKNOWN`| Scope of the classifier: table or column|
`cardinality:` | `UNKNOWN`| Cardinality of the classifier: zero-or-one, one or zero-or-many|
`propagate:` | `boolean`| Does the classifier propagate from scope to scope or is it a one scope marker|
`source-locations:` | `array`| Classifier defined by these set of .sdf files|
## Block: `Function`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| The name of the function [syntax: [[catalog.]schema].function]|
`section:` | `string`| The generic type bounds|
`dialect:` | `Dialect?`| The dialect that provides this function|
`description:` | `string`| A description of this function|
`variadic:` | `UNKNOWN`| Arbitrary number of arguments of an common type out of a list of valid types|
`kind:` | `UNKNOWN`| The function kind|
`parameters:` | `[Parameter]?`| The arguments of this function|
`optional-parameters:` | `[OptionalParameter]?`| The arguments of this function|
`returns:` | `Parameter?`| The results of this function (can be a tuple)|
`binds:` | `array`| The generic type bounds|
`volatility:` | `UNKNOWN`| volatility - The volatility of the function.|
`examples:` | `array`| example - Example use of the function (tuple with input/output)|
`cross-link:` | `string`| cross-link - link to existing documentation, for example: https://prestodb.io/docs/current/functions/datetime.html#truncation-function|
`reclassify:` | `array`| Array of reclassify instructions for changing the attached classifier labels|
`source-locations:` | `array`| Function defined by these set of .sdf files|
`implemented-by:` | `FunctionImplSpec?`| undefined|
`special:` | `boolean`| Function can be called without parentheses, e.g. as if it were a constant, e.g. current_date|
## Enum: `IncludeType`
Value | Description|
| :--- | :------- |
`model` | Contains models, i.e ddls or queries, used for data transformation|
`data-contract` | Contains queries against the data of the models, the check holds if the data returns zero rows|
`code-contract` | Contains queries against the information schema of the models, the check holds if the data returns zero rows|
`code-report` | Contains queries for the information schema of the model|
`data-report` | Contains queries against the data of the models|
`resource` | Contains resources like csv files that are shipped to the service, etc|
`metadata` | Contains meta data like classifiers, etc|
## Enum: `SyncType`
Value | Description|
| :--- | :------- |
`always` | Synchronizes directory on pull and push|
`on-pull` | Synchronizes directory on every pull|
`on-push` | Synchronizes directory on every push|
`never` | Never synchronizes directory|
## Enum: `ExcludeType`
Value | Description|
| :--- | :------- |
`content` | undefined|
`path` | Excludes this path, can be a glob expression|
## Enum: `TableType`
Value | Description|
| :--- | :------- |
`table` | Computed tables have type table|
`external` | Given tables are called external|
`view` | Table Views|
`temporary-view` | Session scoped temporary table views [Spark specific]|
`recursive` | Recursive warehouse tables [SDF specific]|
`system` | System tables (like sdf.information-schema.*)|
`remote-external` | A root table that is managed by an external table provider like Iceberg, Glue, Snowflake, Redshift, etc|
`remote-table` | A derived table that is managed by an external compute platform like Snowflake, Redshift, etc|
`code-contract` | A table representing a code contract query|
`data-contract` | A table representing a data contract query|
`code-report` | A table representing a code report|
`data-report` | A table representing a data report|
`dialect-specific-table` | A dialect specific table, like BigQueries information_schema|
## Enum: `CompressionType`
Value | Description|
| :--- | :------- |
`tar` | undefined|
`bzip2` | BZIP2 Compression (.bz2)|
`gzip` | GZIP Compression (.gzip)|
`none` | None, (default)|
## Enum: `Variadic`
Value | Description|
| :--- | :------- |
`non-uniform` | undefined|
`uniform` | All arguments have the same types|
`even-odd` | All even arguments have one type, odd arguments have another type|
`any` | Any length of arguments, arguments can be different types|
## Enum: `Volatility`
Value | Description|
| :--- | :------- |
`pure` | Pure - An pure function will always return the same output when given the same input.|
`stable` | Stable - A stable function may return different values given the same input across different queries but must return the same value for a given input within a query.|
`volatile` | Volatile - A volatile function may change the return value from evaluation to evaluation. Multiple invocations of a volatile function may return different results when used in the same query.|
## Nested Elements
### Nested element: `IncludePath`
|Field | Type | Description|
| :---- | :--- | :------- |
`path:` | `string`| A filepath|
`type:` | `UNKNOWN`| Type of included artifacts: model | test | stats | metadata | resource|
`default-catalog:` | `string?`| Defines a default catalog for unqualified names. If not set, defaults to the [Workspace] catalog.|
`default-schema:` | `string?`| Defines a default schema for unqualified names. If not set, defaults to the [Workspace] schema.|
`dialect:` | `Dialect?`| The dialect of the included files. If not set, defaults to the [Workspace] dialect.|
`compute:` | `ComputeKind?`| The compute platform for building the included files. If not set, defaults to the [Workspace] compute platform.|
`index:` | `UNKNOWN`| Index method for this include path: scan | table | schema-table | catalog-schema-table|
`sync:` | `UNKNOWN`| Synchronization schema for this include path: always | on-pull | on-push | never|
### Nested element: `Dialect`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `ComputeKind`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `IndexMethod`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `ExcludePath`
|Field | Type | Description|
| :---- | :--- | :------- |
`path:` | `string`| A filepath|
`exclude-type:` | `ExcludeType?`| Type of excluded artifacts|
### Nested element: `WorkspacePath`
|Field | Type | Description|
| :---- | :--- | :------- |
`path:` | `string`| The relative path from this workspace to the referenced workspace, for a Git repo, from the root of the depot to the workspace|
`profile:` | `string?`| The chosen workspace profile (none means default)|
`git:` | `string?`| The Git repo|
`rev:` | `string?`| the Git revision (choose only one of the fields: rev, branch, tag)|
`branch:` | `string?`| the Git branch (choose only one of the fields: rev, branch, tag)|
`tag:` | `string?`| the Git tag (choose only one of the fields: rev, branch, tag)|
### Nested element: `FilePath`
|Field | Type | Description|
| :---- | :--- | :------- |
`path:` | `string`| A filepath|
### Nested element: `SystemTime`
|Field | Type | Description|
| :---- | :--- | :------- |
`secs_since_epoch:` | `integer`| undefined|
`nanos_since_epoch:` | `integer`| undefined|
### Nested element: `Constant`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `Preprocessor`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `Severity`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `Profile`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| The name of this workspace (defaults to the workspace directory name if not given) Name must be set for deployment.|
`description:` | `string`| A description of this workspace|
`repository:` | `string`| The URL of the workspace source repository (defaults to 'none' if no repository is given)|
`remote-location:` | `string`| The default output object store location, e.g. 's3://bucket/key/' where key is optional|
`includes:` | `array`| An array of directories and filenames containing .sql and .sdf.yml files|
`excludes:` | `array`| An array of directories and filenames to be skipped when resolving includes|
`references:` | `array`| An array of paths to other workspaces, i.e. .sql and .yml files|
`dialect:` | `UNKNOWN`| The dialect of this profile. If not set, defaults to Presto dialect|
`compute:` | `UNKNOWN`| The compute platform for this profile. If not set, defaults to Local|
`default-catalog:` | `string`| Defines a default catalog (If not set, defaults to the workspace name)|
`default-schema:` | `string`| Defines a default schema (If not set, defaults to 'pub')|
`vars:` | `object`| A map of named values for setting SQL variables from your environment Ex. -dt: dt, used in SQL as @dt, an in Jinja as {{ dt }}|
`default-profile:` | `string`| Defines the default profile (if not set, defaults to 'dbg')|
`source-locations:` | `array`| Workspace defined by these set of files|
`preprocessor:` | `Preprocessor?`| Experimental: This project has jinja|
`default-severity:` | `UNKNOWN`| Experimental: This is a dbt project.. The default severity for this tables tests and checks|
`is-dbt-project:` | `boolean?`| undefined|
### Nested element: `Column`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| The name of the column|
`description:` | `string`| A description of this column|
`datatype:` | `string?`| The type of this column|
`classifiers:` | `array`| An array of classifier references|
`lineage:` | `Lineage?`| Lineage, a tagged array of column references|
`reclassify:` | `array`| Array of reclassify instructions for changing the attached classifier labels|
`samples:` | `array`| An array of representative literals of this column [experimental!]|
`default-severity:` | `UNKNOWN`| The default severity for this tables tests and checks|
`constraints:` | `array`| undefined|
### Nested element: `Lineage`
|Field | Type | Description|
| :---- | :--- | :------- |
`copy:` | `array`| The output column is computed by copying these upstream columns|
`modify:` | `array`| The output column is computed by transforming these upstream columns|
`scan:` | `array`| These upstream columns are indirectly used to produce the output (e.g. in WHERE or GROUP BY)|
`apply:` | `array`| These functions were used to produce the output column|
### Nested element: `Reclassify`
|Field | Type | Description|
| :---- | :--- | :------- |
`to:` | `string?`| Target classifier|
`from:` | `string?`| Expected source classifier|
### Nested element: `Constraint`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| The name of the constraint|
`test:` | `string`| The type of the constraint|
`severity:` | `UNKNOWN`| The columns that the constraint applies to|
### Nested element: `Partition`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| The name of the partition column|
`description:` | `string?`| A description of the partition column|
`format:` | `string?`| The format of the partition column [use strftime format for date/time] See (guide)[https://docs.sdf.com/guide/schedules]|
### Nested element: `FileFormat`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `Label`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| The name of the label, use "*" to allow arbitrary strings as labels|
`description:` | `string?`| A description of this classifier element|
### Nested element: `Scope`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `Cardinality`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `FunctionKind`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `Parameter`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string?`| The name of the parameter|
`description:` | `string?`| A description of this parameter|
`datatype:` | `string?`| The datatype of this parameter|
`classifier:` | `[string]?`| An array of classifier references|
`constant:` | `string?`| The required constant value of this parameter|
`identifiers:` | `[string]?`| The parameter may appear as identifier, without quote|
### Nested element: `OptionalParameter`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| The name of the parameter|
`description:` | `string?`| A description of this parameter|
`datatype:` | `string`| The datatype of this parameter|
`classifier:` | `[string]?`| An array of classifier references|
`constant:` | `string?`| The required constant value of this parameter|
`identifiers:` | `[string]?`| The parameter may appear as identifier, without quote|
### Nested element: `TypeBound`
|Field | Type | Description|
| :---- | :--- | :------- |
`type-variable:` | `string`| undefined|
`datatypes:` | `array`| undefined|
### Nested element: `Example`
|Field | Type | Description|
| :---- | :--- | :------- |
`input:` | `string`| The sql string corresponding to the input of this example|
`output:` | `string`| The output corresponding to running the input string|
### Nested element: `FunctionImplSpec`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `Plugin`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| The name of the plugin [e.g.: pyspark]|
`image-uri:` | `string?`| Image URI of the plugin [e.g.: docker.io/sdf/pyspark:latest]|
`dockerfile:` | `string?`| Path to the dockerfile of the plugin [e.g.: dockerfile]|
`keep-alive:` | `boolean?`| Whether to keep the plugin container alive after execution|
`includes:` | `array`| An array of directories and filenames containing files processed by this plugin|
### Nested element: `PluginIncludePath`
|Field | Type | Description|
| :---- | :--- | :------- |
`path:` | `string`| A filepath|
`kind:` | `PluginIncludePathKind?`| Type of Plugin Path (Default: queries)|
### Nested element: `PluginIncludePathKind`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `Provider`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| The name of the table provider|
`sources:` | `array`| A list of sources, backed by the table provider, source can use globs, e.g. catalog.schema.*|
`type:` | `UNKNOWN`| The type of the catalog [e.g.: hive]|
`warehouse:` | `string?`| The snowflake warehouse (defaults: the warehouse that was given at sdf Auth)|
`cluster-identifier:` | `string?`| The cluster identifier for redshift server|
`source-locations:` | `array`| undefined|
`batch-size:` | `integer?`| undefined|
### Nested element: `CatalogType`
|Field | Type | Description|
| :---- | :--- | :------- |
### Nested element: `Config`
|Field | Type | Description|
| :---- | :--- | :------- |
`name:` | `string`| The name of the configuration section|
`description:` | `string?`| A description of this configuration section|
`properties:` | `object?`| undefined|

